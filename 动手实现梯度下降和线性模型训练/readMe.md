# 实验001 动手实现梯度下降和线性模型的训练并且比较梯度下降和拟牛顿法的速度

## 实验目标

- 动手实现梯度下降算法
- 通过实现的算法进行线性模型的训练
- 比较梯度下降原生实现、手动实现和拟牛顿法的性能差距

## 实验设计

1. 实现通过给出一个具体的线性模型生成相应的带噪声的数据集
2. 实现梯度下降算法
3. 实现拟牛顿法
4. 使用框架自带实现
5. 进行线性模型的训练

## 实验结果

- V1

```shell
L (Lipschitz): 0.0020000000000000018
BFGS success: False nit: 500 time: 0.10105513700545998 final loss: 0.004604025970992544
GD final loss: 0.0046034566746033555 param_err: 3.9953010832936897
BFGS final loss: 0.004604025970992544 param_err: 3.988922119130701
```

![20250921100756](https://cdn.jsdelivr.net/gh/jagger235711/coooool@main/img/20250921100756.png)
![20250921101354](https://cdn.jsdelivr.net/gh/jagger235711/coooool@main/img/20250921101354.png)
![20250921100846](https://cdn.jsdelivr.net/gh/jagger235711/coooool@main/img/20250921100846.png)
---

- 不足
  - loss下降太快
  - 对比不显著
- 问题及原因分析
  - 为什么BFGS直接就是一条直线？

1. loss下降太快是因为问题过于简单、超参数设计太好，想要减慢速度可以增加噪音强度、调整超参数
2. BFGS是直线是因为直接用的最终结果，而不是每次更新，已修正
